{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41579b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_and_transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_and_transform_data(SEED=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of subsets\n",
    "print(f\"X train shape:\\t\", X_train.shape)\n",
    "print(f\"y train shape:\\t\", y_train.shape)\n",
    "print(f\"X val shape:\\t\", X_val.shape)\n",
    "print(f\"y val shape:\\t\", y_val.shape)\n",
    "print(f\"X test shape:\\t\", X_test.shape)\n",
    "print(f\"y test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 7\n",
    "n_runs = 10\n",
    "test_image_idx = 0\n",
    "\n",
    "# Storage for all runs\n",
    "all_histories = []\n",
    "all_test_accs = []\n",
    "all_test_losses = []\n",
    "all_predictions = []\n",
    "all_sensitivities = []\n",
    "all_specificities = []\n",
    "all_activations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9585b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "for run in range(n_runs):\n",
    "    print(f\"\\n--- Run {run + 1}/{n_runs} ---\")\n",
    "    \n",
    "    # Clear session and rebuild model for each run\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Build model\n",
    "    GRU = keras.Sequential()\n",
    "    GRU.add(keras.Input(shape=(480, 480)))\n",
    "    GRU.add(layers.GRU(units=240, return_sequences=True, name='gru1'))\n",
    "    GRU.add(layers.GRU(units=120, name='gru2'))\n",
    "    GRU.add(layers.Dense(units=1, activation=\"sigmoid\", name='output'))\n",
    "    \n",
    "    # Compile\n",
    "    GRU.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Train\n",
    "    trainer = GRU.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                     batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = GRU.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Store predictions for confusion matrix\n",
    "    y_pred = GRU.predict(X_test, verbose=0)\n",
    "    all_predictions.append(y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    y_pred_class = (y_pred > 0.5).astype(int).flatten()\n",
    "    cm = confusion_matrix(y_test, y_pred_class)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    # Extract activations\n",
    "    test_image = X_test[test_image_idx:test_image_idx+1]\n",
    "    gru1_layer = GRU.get_layer('gru1')\n",
    "    activation_model = keras.Model(inputs=GRU.layers[0].input, outputs=gru1_layer.output)\n",
    "    gru1_output = activation_model.predict(test_image, verbose=0)[0]\n",
    "    timestep_importance = np.abs(gru1_output).mean(axis=1)\n",
    "    \n",
    "    # Store all results including histories\n",
    "    all_histories.append(trainer.history)\n",
    "    all_activations.append(timestep_importance)\n",
    "    \n",
    "    # Store in results list\n",
    "    results.append({\n",
    "        'Run': run + 1,\n",
    "        'Layer-Config': 'GRU(240) -> GRU(120)',\n",
    "        'Batch-Size': batch_size,\n",
    "        'n-Epochs': epochs,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Test Loss': test_loss,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity\n",
    "    })\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Save run results\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"CSV results/GRU_run_results_final.csv\", index=False)\n",
    "\n",
    "# Compute and save training history\n",
    "mean_train_acc = np.mean([h['accuracy'] for h in all_histories], axis=0)\n",
    "mean_val_acc = np.mean([h['val_accuracy'] for h in all_histories], axis=0)\n",
    "mean_train_loss = np.mean([h['loss'] for h in all_histories], axis=0)\n",
    "mean_val_loss = np.mean([h['val_loss'] for h in all_histories], axis=0)\n",
    "\n",
    "history_df = pd.DataFrame({\n",
    "    'epoch': range(1, len(mean_train_acc) + 1),\n",
    "    'mean_train_accuracy': mean_train_acc,\n",
    "    'mean_val_accuracy': mean_val_acc,\n",
    "    'mean_train_loss': mean_train_loss,\n",
    "    'mean_val_loss': mean_val_loss\n",
    "})\n",
    "history_df.to_csv(\"CSV results/GRU_training_history_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from CSV\n",
    "df_results = pd.read_csv(\"CSV results/GRU_results_final.csv\")\n",
    "\n",
    "# Compute statistics\n",
    "mean_test_acc = df_results['Test Accuracy'].mean()\n",
    "mean_test_loss = df_results['Test Loss'].mean()\n",
    "mean_sensitivity = df_results['Sensitivity'].mean()\n",
    "mean_specificity = df_results['Specificity'].mean()\n",
    "\n",
    "print(f\"\\n=== Final Results Over {len(df_results)} Runs ===\")\n",
    "print(f\"Test Accuracy: {mean_test_acc:.4f}\")\n",
    "print(f\"Test Loss: {mean_test_loss:.4f}\")\n",
    "print(f\"Sensitivity: {mean_sensitivity:.4f}\")\n",
    "print(f\"Specificity: {mean_specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dacae8",
   "metadata": {},
   "source": [
    "### Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Widths in inches from revtex4's layout\n",
    "columnwidth = 4.375\n",
    "fig_width = columnwidth\n",
    "fig_height = columnwidth / 1.618\n",
    "fig_size = [fig_width, fig_height]\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],\n",
    "    \"font.size\": 14.0, \n",
    "    \"axes.labelsize\": 14.0,\n",
    "    \"legend.fontsize\": 12.0,\n",
    "    \"xtick.labelsize\": 12.0,\n",
    "    \"ytick.labelsize\": 12.0,\n",
    "    \"figure.figsize\": fig_size,\n",
    "    \"savefig.dpi\": 300,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Activation Heatmap\n",
    "fig_size_square = [columnwidth * 1.5, columnwidth * 1.5]\n",
    "fig, ax = plt.subplots(figsize=fig_size_square)\n",
    "\n",
    "mean_activation = np.mean(all_activations, axis=0)\n",
    "test_image = X_test[test_image_idx]\n",
    "\n",
    "ax.imshow(test_image, cmap='gray')\n",
    "heatmap = ax.imshow(mean_activation.reshape(-1, 1).repeat(480, axis=1), \n",
    "                    cmap='coolwarm', alpha=0.6, vmin=mean_activation.min(), \n",
    "                    vmax=mean_activation.max())\n",
    "\n",
    "ax.set_title(f'RNN Activation Heatmap')\n",
    "ax.axis('off')\n",
    "\n",
    "cbar = plt.colorbar(heatmap, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Activation Strength', rotation=270, labelpad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gru_activation_heatmap.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "history_df = pd.read_csv(\"CSV results/GRU_training_history_final.csv\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['mean_train_accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_df['mean_val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'GRU Model Accuracy (Mean over {n_runs} runs)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_df['mean_train_loss'], label='Train Loss')\n",
    "plt.plot(history_df['mean_val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'GRU Model Loss (Mean over {n_runs} runs)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b259620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute mean confusion matrix across all runs\n",
    "all_cms = []\n",
    "for y_pred in all_predictions:\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "    all_cms.append(cm)\n",
    "\n",
    "mean_cm = np.mean(all_cms, axis=0).astype(int)\n",
    "mean_cm_flipped = np.flipud(mean_cm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(columnwidth, columnwidth*(3/4)))\n",
    "sns.heatmap(mean_cm_flipped, annot=True, fmt='d', ax=ax, cmap=\"Greens\", \n",
    "            yticklabels=['Pneumonia', 'No Pneumonia'],\n",
    "            xticklabels=['No Pneumonia', 'Pneumonia'])\n",
    "ax.set_title(f\"Confusion Matrix\", \n",
    "             fontsize=16, pad=20)\n",
    "\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=14)\n",
    "ax.set_ylabel(\"True Label\", fontsize=14)\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Sensitivity and Specificity as bar chart\n",
    "fig, ax = plt.subplots(figsize=(columnwidth*0.8, columnwidth*(3/4)))\n",
    "\n",
    "metrics = ['Sensitivity', 'Specificity']\n",
    "values = [mean_sensitivity, mean_specificity]\n",
    "std_values = [np.std(all_sensitivities), np.std(all_specificities)]\n",
    "\n",
    "x_pos = np.arange(len(metrics))\n",
    "bars = ax.bar(x_pos, values, yerr=std_values, capsize=8, \n",
    "               color=['#2ecc71', '#3498db'], alpha=0.8, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Model Performance Metrics', fontsize=14, pad=15)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(metrics, fontsize=11)\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
    "\n",
    "for i, (val, std) in enumerate(zip(values, std_values)):\n",
    "    ax.text(i, val + std + 0.03, f'{val:.3f}', \n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Sensitivity and Specificity across runs\n",
    "fig, ax = plt.subplots(figsize=(columnwidth*1.2, columnwidth*(3/4)))\n",
    "\n",
    "actual_runs = len(all_sensitivities)\n",
    "runs = np.arange(1, actual_runs + 1)\n",
    "\n",
    "ax.plot(runs, all_sensitivities, marker='o', label='Sensitivity', \n",
    "        linewidth=2, markersize=6, color='#2ecc71')\n",
    "ax.plot(runs, all_specificities, marker='s', label='Specificity', \n",
    "        linewidth=2, markersize=6, color='#3498db')\n",
    "\n",
    "ax.axhline(y=mean_sensitivity, color='#2ecc71', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "ax.axhline(y=mean_specificity, color='#3498db', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "\n",
    "ax.fill_between(runs, \n",
    "                mean_sensitivity - np.std(all_sensitivities), \n",
    "                mean_sensitivity + np.std(all_sensitivities), \n",
    "                alpha=0.15, color='#2ecc71')\n",
    "ax.fill_between(runs, \n",
    "                mean_specificity - np.std(all_specificities), \n",
    "                mean_specificity + np.std(all_specificities), \n",
    "                alpha=0.15, color='#3498db')\n",
    "\n",
    "ax.set_xlabel('Run Number', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Performance Across Training Runs', fontsize=14, pad=15)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xticks(runs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7e2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60754791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
