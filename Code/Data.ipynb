{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1cfddf7",
   "metadata": {},
   "source": [
    "# Dataset import and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cbd82",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub, os, shutil, random, torch, cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ad9f6",
   "metadata": {},
   "source": [
    "**Fixed random seed for reproducability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c150214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix result (adapted from Monshi et al 2021)\n",
    "# https://github.com/MaramMonshi/CovidXrayNet/blob/main/DataAugmentation/1-resize.ipynb \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed2ab2",
   "metadata": {},
   "source": [
    "**Dataset import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e761e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy to current directory\n",
    "target_dir = \"chest_xray_data\"\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "\n",
    "    # Download the dataset\n",
    "    path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "    print(\"Downloaded to cache:\", path)\n",
    "\n",
    "    shutil.copytree(path, target_dir)\n",
    "    print(f\"Dataset copied to: {target_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Dataset already exists at: {target_dir}\")\n",
    "\n",
    "print(\"\\nDataset ready at:\", os.path.abspath(target_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64390471",
   "metadata": {},
   "source": [
    "### Dataset reshuffle and train, test, val split 80/10/10\n",
    "\n",
    "Copied from: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/discussion/485689 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bf443",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'chest_xray_data/chest_xray'\n",
    "new_dataset_path = 'chest_xray_data_split'\n",
    "\n",
    "if not os.path.exists(new_dataset_path):\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in ['NORMAL', 'PNEUMONIA']:\n",
    "            os.makedirs(f'{new_dataset_path}/{split}/{cls}', exist_ok=True)\n",
    "\n",
    "    for cls in ['NORMAL', 'PNEUMONIA']:\n",
    "        all_files = []\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            source_folder = f'{dataset_path}/{split}/{cls}'\n",
    "            files = os.listdir(source_folder)\n",
    "            all_files.extend([(file, source_folder) for file in files])\n",
    "\n",
    "        random.shuffle(all_files)\n",
    "\n",
    "        train_files = all_files[:int(len(all_files)*0.8)]\n",
    "        val_files = all_files[int(len(all_files)*0.8):int(len(all_files)*0.9)]\n",
    "        test_files = all_files[int(len(all_files)*0.9):]\n",
    "\n",
    "        for file, source_folder in train_files:\n",
    "            dest = f'{new_dataset_path}/train/{cls}/{file}'\n",
    "            shutil.copy(f'{source_folder}/{file}', dest)\n",
    "\n",
    "        for file, source_folder in val_files:\n",
    "            dest = f'{new_dataset_path}/val/{cls}/{file}'\n",
    "            shutil.copy(f'{source_folder}/{file}', dest)\n",
    "\n",
    "        for file, source_folder in test_files:\n",
    "            dest = f'{new_dataset_path}/test/{cls}/{file}'\n",
    "            shutil.copy(f'{source_folder}/{file}', dest)  \n",
    "\n",
    "    print(\"\\nDataset ready at:\", os.path.abspath(new_dataset_path))\n",
    "   \n",
    "else:\n",
    "    print(f\"Dataset already exists at: {new_dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30381e8c",
   "metadata": {},
   "source": [
    "**Find the smallest and largest image dimensions present in the dataset** \\\n",
    "Used to investigate variation in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'chest_xray_data_split'\n",
    "sizes = []\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for cls in ['NORMAL', 'PNEUMONIA']:\n",
    "        folder = f'{dataset_path}/{split}/{cls}'\n",
    "        for filename in os.listdir(folder):\n",
    "            img = Image.open(os.path.join(folder, filename))\n",
    "            width, height = img.size\n",
    "            sizes.append((width * height, width, height, filename))\n",
    "\n",
    "sizes.sort()  # Sort from smallest to largest\n",
    "\n",
    "print(\"Top 5 smallest images:\")\n",
    "for i in range(5):\n",
    "    pixels, w, h, name = sizes[i]\n",
    "    print(f\"{name}: {w} x {h} ({pixels:,} pixels)\")\n",
    "\n",
    "\n",
    "sizes.sort(reverse=True)  # Sort from largest to smallest\n",
    "\n",
    "print(\"\\nTop 5 largest images:\")\n",
    "for i in range(5):\n",
    "    pixels, w, h, name = sizes[i]\n",
    "    print(f\"{name}: {w} x {h} ({pixels:,} pixels)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd30fa34",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.5\n",
    "std = 0.5\n",
    "\n",
    "# Define the transforms to do for training data\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Define the transforms to do for validation and testing data\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load datasets with progress bar\n",
    "def load_data(path, train_aug=True):\n",
    "    transform = train_transform if train_aug else val_test_transform\n",
    "    dataset = datasets.ImageFolder(path, transform=transform)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in tqdm(range(len(dataset)), desc=f\"Loading {path.split('/')[-1]}\"):\n",
    "        img, label = dataset[i]\n",
    "        images.append(img.numpy().squeeze())\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = load_data('chest_xray_data_split/train', train_aug=True)\n",
    "X_val, y_val = load_data('chest_xray_data_split/val', train_aug=False)\n",
    "X_test, y_test = load_data('chest_xray_data_split/test', train_aug=False)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587b897",
   "metadata": {},
   "source": [
    "**Visualization of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb47823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    return np.clip(img * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "# Get 4 samples from each class\n",
    "normal_indices = np.where(y_train == 0)[0][:4]\n",
    "pneumonia_indices = np.where(y_train == 1)[0][:4]\n",
    "indices = np.concatenate([normal_indices, pneumonia_indices])\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i in range(8):\n",
    "    row, col = i // 4, i % 4\n",
    "    idx = indices[i]\n",
    "    img = denormalize(X_train[idx])\n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(['NORMAL', 'PNEUMONIA'][y_train[idx]])\n",
    "    axes[row, col].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    return np.clip(img * 0.5 + 0.5, 0, 1)\n",
    "\n",
    "# Get 2 samples from each class\n",
    "normal_indices = np.where(y_val == 0)[0][:2]\n",
    "pneumonia_indices = np.where(y_val == 1)[0][:2]\n",
    "indices = np.concatenate([normal_indices, pneumonia_indices])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "for i in range(4):\n",
    "    row, col = i // 2, i % 2\n",
    "    idx = indices[i]\n",
    "    img = denormalize(X_val[idx])\n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(['NORMAL', 'PNEUMONIA'][y_train[idx]])\n",
    "    axes[row, col].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744536d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
