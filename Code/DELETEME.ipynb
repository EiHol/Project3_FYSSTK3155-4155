{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260bb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import copy\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from activation_functions import *\n",
    "from cost_functions import *\n",
    "from FFNN import *\n",
    "\n",
    "# Setting the random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9015e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "# Extract data (features) and target (labels)\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# Scaling the mnist pixel values from 0-255 to 0-1\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf98c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into testing, training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_one_hot(y_train)\n",
    "y_test = to_one_hot(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1e59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Widths in inches from revtex4's layout\n",
    "# Single column ~3.375in, double column ~7in\n",
    "columnwidth = 3.375  # use 7.0 for two-column-wide figures\n",
    "\n",
    "# Compute figure size (width, height)\n",
    "fig_width = columnwidth\n",
    "fig_height = columnwidth / 1.618  # golden ratio for aesthetics\n",
    "fig_size = [fig_width, fig_height]\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    # Use LaTeX for text rendering\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],  # empty means use LaTeX default (Computer Modern)\n",
    "    \"font.size\": 10.0,  # matches REVTeX's \\normalsize\n",
    "\n",
    "    # Adjust tick and label sizes\n",
    "    \"axes.labelsize\": 10.0,\n",
    "    \"legend.fontsize\": 8.0,\n",
    "    \"xtick.labelsize\": 8.0,\n",
    "    \"ytick.labelsize\": 8.0,\n",
    "\n",
    "    # Figure dimensions\n",
    "    \"figure.figsize\": fig_size,\n",
    "\n",
    "    # Save with good resolution\n",
    "    \"savefig.dpi\": 300,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35d04c",
   "metadata": {},
   "source": [
    "## Without reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "958f3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc = 0.9361, Test Acc = 0.9607\n",
      "Epoch 25: Train Acc = 1.0000, Test Acc = 0.9814\n",
      "Epoch 50: Train Acc = 1.0000, Test Acc = 0.9815\n",
      "Epoch 75: Train Acc = 1.0000, Test Acc = 0.9814\n",
      "Epoch 100: Train Acc = 1.0000, Test Acc = 0.9814\n",
      "\n",
      "Keras Results (No Regularization):\n",
      "   epoch  train_acc  test_acc  overfit_gap\n",
      "0      1   0.936125  0.960714    -0.024589\n",
      "1      2   0.972018  0.969500     0.002518\n",
      "2      3   0.980018  0.972643     0.007375\n",
      "3      4   0.983786  0.971500     0.012286\n",
      "4      5   0.986804  0.974071     0.012732\n",
      "5      6   0.989321  0.974071     0.015250\n",
      "6      7   0.991554  0.975071     0.016482\n",
      "7      8   0.993714  0.976000     0.017714\n",
      "8      9   0.995464  0.977571     0.017893\n",
      "9     10   0.996321  0.978357     0.017964\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert one-hot encoded labels back to integer labels for Keras\n",
    "y_train_keras = np.argmax(y_train, axis=1)\n",
    "y_test_keras = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Define parameters matching implementation\n",
    "epochs = 100\n",
    "eta = 0.01\n",
    "\n",
    "# Store results\n",
    "keras_all_runs_results = []\n",
    "\n",
    "# Create model matching architecture: 784 -> 500 -> 10\n",
    "# NO regularization\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(500, activation='sigmoid', \n",
    "                 input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Use RMSprop optimizer to match train_network_SRMSprop\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=eta)\n",
    "\n",
    "# Compile model with categorical crossentropy\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train for one epoch at a time to track progress like implementation\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Train for 1 epoch\n",
    "    history = model.fit(\n",
    "        X_train, y_train_keras,\n",
    "        epochs=1,\n",
    "        verbose=0,\n",
    "        validation_data=(X_test, y_test_keras)\n",
    "    )\n",
    "    \n",
    "    # Get accuracy\n",
    "    train_acc = history.history['accuracy'][0]\n",
    "    test_acc = history.history['val_accuracy'][0]\n",
    "    \n",
    "    # Calculate overfitting gap\n",
    "    overfit_gap = train_acc - test_acc\n",
    "    \n",
    "    # Store results\n",
    "    keras_all_runs_results.append({\n",
    "        'epoch': epoch,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfit_gap': overfit_gap\n",
    "    })\n",
    "    \n",
    "    # Print progress every 25 epochs\n",
    "    if epoch % 25 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_keras_all_runs = pd.DataFrame(keras_all_runs_results)\n",
    "\n",
    "print(\"\\nKeras Results (No Regularization):\")\n",
    "print(df_keras_all_runs.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3956e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keras_all_runs.to_csv(\"MNIST-full_Keras_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c37a2b",
   "metadata": {},
   "source": [
    "## With reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb73a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc = 0.8427, Test Acc = 0.8631\n",
      "Epoch 25: Train Acc = 0.8965, Test Acc = 0.8946\n",
      "Epoch 50: Train Acc = 0.8960, Test Acc = 0.9004\n",
      "Epoch 75: Train Acc = 0.8987, Test Acc = 0.9069\n",
      "Epoch 100: Train Acc = 0.8962, Test Acc = 0.9136\n"
     ]
    }
   ],
   "source": [
    "# Define parameters matching implementation\n",
    "epochs = 100\n",
    "eta = 0.01\n",
    "l2_lmbda = 0.001\n",
    "\n",
    "# Store results across all runs\n",
    "keras_all_runs_results = []\n",
    "\n",
    "\n",
    "# Create model matching architecture: 784 -> 500 -> 10\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(500, activation='sigmoid', \n",
    "                    input_shape=(X_train.shape[1],),\n",
    "                    kernel_regularizer=regularizers.l2(l2_lmbda)),\n",
    "    layers.Dense(10, activation='softmax',\n",
    "                    kernel_regularizer=regularizers.l2(l2_lmbda))\n",
    "])\n",
    "\n",
    "# Use RMSprop optimizer to match train_network_SRMSprop\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=eta)\n",
    "\n",
    "# Compile model with categorical crossentropy\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train for one epoch at a time to track progress like implementation\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Train for 1 epoch\n",
    "    history = model.fit(\n",
    "        X_train, y_train_keras,\n",
    "        epochs=1,\n",
    "        verbose=0,\n",
    "        validation_data=(X_test, y_test_keras)\n",
    "    )\n",
    "    \n",
    "    # Get accuracy\n",
    "    train_acc = history.history['accuracy'][0]\n",
    "    test_acc = history.history['val_accuracy'][0]\n",
    "    \n",
    "    # Calculate overfitting gap\n",
    "    overfit_gap = train_acc - test_acc\n",
    "    \n",
    "    # Store results\n",
    "    keras_all_runs_results.append({\n",
    "        'epoch': epoch,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfit_gap': overfit_gap\n",
    "    })\n",
    "    \n",
    "    # Print progress every 25 epochs\n",
    "    if epoch % 25 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_keras_all_runs_reg = pd.DataFrame(keras_all_runs_results)\n",
    "\n",
    "# Save as CSV\n",
    "df_keras_all_runs_reg.to_csv(\"MNIST-full_Keras_reg_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9628677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e54dd70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
