{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf44d7e",
   "metadata": {},
   "source": [
    "# Testing FFNN on classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae9e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from activation_functions import *\n",
    "from cost_functions import *\n",
    "from FFNN import *\n",
    "\n",
    "# Setting the random seed\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5336aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "# Extract data (features) and target (labels)\n",
    "X = mnist.data\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66ee301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the mnist pixel values from 0-255 to 0-1\n",
    "#X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc90028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into testing an training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10edc806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6754f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input_size = 784\n",
    "layer_output_sizes = [1000, 500, 100, 10]\n",
    "activation_funcs = [sigmoid, ReLU, ReLU, softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cec28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork(network_input_size, layer_output_sizes, activation_funcs, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77a11fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: overflow encountered in exp\n",
      "  return f_raw(*args, **kwargs)\n",
      "c:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  return f_raw(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (25,10) (25,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m eta = \u001b[32m0.01\u001b[39m\n\u001b[32m      2\u001b[39m epochs = \u001b[32m100\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrain_network_stocastic_ADAM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\Code\\FFNN.py:304\u001b[39m, in \u001b[36mtrain_network_stocastic_ADAM\u001b[39m\u001b[34m(neural_network, inputs, targets, eta, beta1, beta2, epochs, batch_size)\u001b[39m\n\u001b[32m    301\u001b[39m batch_targets = shuffled_targets[j : j + batch_size]\n\u001b[32m    303\u001b[39m \u001b[38;5;66;03m# Compute gradients for all layers\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m layers_grad = \u001b[43mneural_network\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Update weights using gradient descent\u001b[39;00m\n\u001b[32m    306\u001b[39m neural_network.update_params_ADAM(layers_grad, eta, beta1, beta2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\Code\\FFNN.py:87\u001b[39m, in \u001b[36mNeuralNetwork.compute_gradients\u001b[39m\u001b[34m(self, inputs, targets)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, targets):\n\u001b[32m     86\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Computes the gradients for each layer and returns all gradients\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     layers_grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layers_grad\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\wrap_util.py:23\u001b[39m, in \u001b[36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     22\u001b[39m     x = \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munary_operator\u001b[49m\u001b[43m(\u001b[49m\u001b[43munary_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mnary_op_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnary_op_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\differential_operators.py:30\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(fun, x)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;129m@unary_to_nary\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrad\u001b[39m(fun, x):\n\u001b[32m     25\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m    Returns a function which computes the gradient of `fun` with respect to\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    positional argument number `argnum`. The returned function takes the same\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m    arguments as `fun`, but returns the gradient instead. The function `fun`\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m    should be scalar-valued. The gradient has the same type as the argument.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     vjp, ans = \u001b[43m_make_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans).size == \u001b[32m1\u001b[39m:\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     33\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mGrad only applies to real scalar-output functions. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\core.py:12\u001b[39m, in \u001b[36mmake_vjp\u001b[39m\u001b[34m(fun, x)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_vjp\u001b[39m(fun, x):\n\u001b[32m     11\u001b[39m     start_node = VJPNode.new_root()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     end_value, end_node = \u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end_node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvjp\u001b[39m(g):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:12\u001b[39m, in \u001b[36mtrace\u001b[39m\u001b[34m(start_node, fun, x)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trace_stack.new_trace() \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[32m     11\u001b[39m     start_box = new_box(x, t, start_node)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     end_box = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_box\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isbox(end_box) \u001b[38;5;129;01mand\u001b[39;00m end_box._trace == start_box._trace:\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m end_box._value, end_box._node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\wrap_util.py:17\u001b[39m, in \u001b[36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     16\u001b[39m     subargs = subvals(args, \u001b[38;5;28mzip\u001b[39m(argnum, x))\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43msubargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\Code\\FFNN.py:78\u001b[39m, in \u001b[36mNeuralNetwork._create_gradient_func.<locals>.cost\u001b[39m\u001b[34m(layers, inputs, targets)\u001b[39m\n\u001b[32m     76\u001b[39m     a = activation_func(z)\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Return cost function value\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcost_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\Code\\cost_functions.py:10\u001b[39m, in \u001b[36mmse\u001b[39m\u001b[34m(predict, target)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmse\u001b[39m(predict, target):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean((\u001b[43mpredict\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m) ** \u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_boxes.py:44\u001b[39m, in \u001b[36mArrayBox.__sub__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubtract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:50\u001b[39m, in \u001b[36mprimitive.<locals>.f_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m parents = \u001b[38;5;28mtuple\u001b[39m(box._node \u001b[38;5;28;01mfor\u001b[39;00m _, box \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[32m     49\u001b[39m argnums = \u001b[38;5;28mtuple\u001b[39m(argnum \u001b[38;5;28;01mfor\u001b[39;00m argnum, _ \u001b[38;5;129;01min\u001b[39;00m boxed_args)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m ans = \u001b[43mf_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m node = node_constructor(ans, f_wrapped, argvals, kwargs, argnums, parents)\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eirik\\Documents\\FYSSTK3155\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54\u001b[39m, in \u001b[36mprimitive.<locals>.f_wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (25,10) (25,) "
     ]
    }
   ],
   "source": [
    "eta = 0.01\n",
    "epochs = 100\n",
    "\n",
    "train_network_stocastic_ADAM(NN, X_train, y_train, eta=eta, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6aa29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
