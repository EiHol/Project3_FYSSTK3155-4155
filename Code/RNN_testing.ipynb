{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3387d69",
   "metadata": {},
   "source": [
    "# Test files for Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38803fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead1f472",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_and_transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_and_transform_data(SEED=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of subsets\n",
    "print(f\"X train shape:\\t\", X_train.shape)\n",
    "print(f\"y train shape:\\t\", y_train.shape)\n",
    "print(f\"X val shape:\\t\", X_val.shape)\n",
    "print(f\"y val shape:\\t\", y_val.shape)\n",
    "print(f\"X test shape:\\t\", X_test.shape)\n",
    "print(f\"y test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f837985",
   "metadata": {},
   "source": [
    "### Initial testing for RNN, LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3775b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = keras.Sequential()                          # Create a base sequential model\n",
    "RNN.add(keras.Input(shape=(480, 480)))            # Set the input shape\n",
    "RNN.add(layers.SimpleRNN(units=240))      # Add a simple RNN layer\n",
    "RNN.add(layers.Dense(units=2, activation=\"softmax\")) # Output layer\n",
    "\n",
    "# Get a summary of model configuration\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM = keras.Sequential()                          # Create a base sequential model\n",
    "LSTM.add(keras.Input(shape=(480, 480)))            # Set the input shape\n",
    "LSTM.add(layers.LSTM(units=240))      # Add a LSTM layer\n",
    "LSTM.add(layers.Dense(units=2, activation=\"softmax\")) # Output layer\n",
    "\n",
    "# Get a summary of model configuration\n",
    "LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU = keras.Sequential()                          # Create a base sequential model\n",
    "GRU.add(keras.Input(shape=(480, 480)))            # Set the input shape\n",
    "GRU.add(layers.GRU(units=240))      # Add a GRU layer\n",
    "GRU.add(layers.Dense(units=2, activation=\"softmax\")) # Output layer\n",
    "\n",
    "# Get a summary of model configuration\n",
    "GRU.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f504c4e",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "RNN_trainer = RNN.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "RNN_test_loss, RNN_test_acc = RNN.evaluate(X_test, y_test)\n",
    "print(f'RNN Test Accuracy: {RNN_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b418fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "LSTM_trainer = LSTM.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "LSTM_test_loss, LSTM_test_acc = LSTM.evaluate(X_test, y_test)\n",
    "print(f'LSTM Test Accuracy: {LSTM_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc372fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "GRU_trainer = GRU.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "GRU_test_loss, GRU_test_acc = GRU.evaluate(X_test, y_test)\n",
    "print(f'GRU Test Accuracy: {GRU_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81787991",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df71294",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(RNN_trainer.history['val_accuracy'], label='RNN Val Accuracy')\n",
    "ax1.plot(LSTM_trainer.history['val_accuracy'], label='LSTM Val Accuracy')\n",
    "ax1.plot(GRU_trainer.history['val_accuracy'], label='GRU Val Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(RNN_trainer.history['val_loss'], label='RNN Val Loss')\n",
    "ax2.plot(LSTM_trainer.history['val_loss'], label='LSTM Val Loss')\n",
    "ax2.plot(GRU_trainer.history['val_loss'], label='GRU Val Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RNN.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# 3. Print test metrics\n",
    "test_loss, test_acc = RNN.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b367c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LSTM.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# 3. Print test metrics\n",
    "test_loss, test_acc = LSTM.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = GRU.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# 3. Print test metrics\n",
    "test_loss, test_acc = GRU.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76641c8",
   "metadata": {},
   "source": [
    "## Initial Rough Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1311d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from load_data import load_and_transform_data\n",
    "\n",
    "# Speed optimizations\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(\"CSV results\", exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "units = [15, 30, 60, 120, 240]\n",
    "dropout = [0.0, 0.15, 0.3]\n",
    "epochs = [10]\n",
    "n_layers = [1, 2, 3]\n",
    "layer_types = [layers.SimpleRNN, layers.LSTM, layers.GRU]\n",
    "\n",
    "# Generate all layer configurations\n",
    "def generate_layer_configs(n_layers, layer_types, units):\n",
    "    \"\"\"Generate all possible layer type combinations\"\"\"\n",
    "    if n_layers == 1:\n",
    "        return [(typ,) for typ in layer_types]\n",
    "    elif n_layers == 2:\n",
    "        return list(itertools.product(layer_types, layer_types))\n",
    "    elif n_layers == 3:\n",
    "        return list(itertools.product(layer_types, layer_types, layer_types))\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from load_data import load_and_transform_data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_and_transform_data(SEED=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total combinations\n",
    "layer_configs = []\n",
    "for n_lay in n_layers:\n",
    "    layer_configs.extend([(n_lay, config) for config in generate_layer_configs(n_lay, layer_types, units)])\n",
    "\n",
    "total_combinations = len(units) * len(dropout) * len(epochs) * len(layer_configs)\n",
    "print(f\"Total combinations: {total_combinations}\")\n",
    "\n",
    "# Store results\n",
    "results1 = []\n",
    "\n",
    "# Train all models\n",
    "for idx, (u, drop, ep, (n_lay, layer_config)) in enumerate(tqdm(\n",
    "    itertools.product(units, dropout, epochs, layer_configs), \n",
    "    total=total_combinations)):\n",
    "    \n",
    "    # Clear previous sessions\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Build model based on layer configuration\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(480, 480)))\n",
    "    \n",
    "    # Add layers\n",
    "    for i, layer_type in enumerate(layer_config):\n",
    "        return_sequences = (i < len(layer_config) - 1)  # True for all but last layer\n",
    "        model.add(layer_type(units=u, dropout=drop, return_sequences=return_sequences))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(units=2, activation=\"softmax\"))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    # Train with early stopping\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, verbose=0)\n",
    "    \n",
    "    trainer = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                       epochs=ep, verbose=0, callbacks=[early_stop])\n",
    "\n",
    "    # Get metrics\n",
    "    val_acc = trainer.history['val_accuracy'][-1]\n",
    "    val_loss = trainer.history['val_loss'][-1]\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    # Create layer type string\n",
    "    layer_names = [typ.__name__ for typ in layer_config]\n",
    "    layer_str = ' -> '.join(layer_names)\n",
    "\n",
    "    # Store results\n",
    "    results1.append({\n",
    "        'n-Layers': n_lay,\n",
    "        'Layer-Config': layer_str,\n",
    "        'n-Units': u,\n",
    "        'Dropout': drop,\n",
    "        'n-Epochs': ep,\n",
    "        'Val Accuracy': val_acc,\n",
    "        'Val Loss': val_loss,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Test Loss': test_loss\n",
    "    })\n",
    "    \n",
    "    # Save progress\n",
    "    pd.DataFrame(results1).to_csv(\"CSV results/GRU_results_rough_temp.csv\", index=False)\n",
    "\n",
    "# Save final results\n",
    "df_results1 = pd.DataFrame(results1)\n",
    "df_results1.to_csv(\"CSV results/GRU_results_rough.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top configurations\n",
    "top_20 = df_results1.nlargest(20, 'Val Accuracy')\n",
    "print(f\"\\nComplete! {len(results1)} models trained\")\n",
    "print(\"\\nTop 20 Configurations:\")\n",
    "print(top_20[['Layer-Config', 'n-Units', 'Dropout', 'Val Accuracy', 'Test Accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e77c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "df_results1 = pd.read_csv(\"CSV results/GRU_results_rough.csv\")\n",
    "\n",
    "# Top 50\n",
    "top_16 = df_results1.nlargest(14, 'Val Accuracy')\n",
    "print(\"\\nTop 50 configurations:\")\n",
    "print(top_16[['N-type', 'n-Units', 'Dropout', 'n-Epochs', 'Val Accuracy', 'Test Accuracy']])\n",
    "\n",
    "# Best model\n",
    "print(\"\\nBest model:\")\n",
    "print(df_results1.iloc[df_results1['Val Accuracy'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd47052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts\n",
    "print(\"\\nTop 50 distributions:\")\n",
    "for col in ['N-type', 'n-Units', 'Dropout', 'n-Epochs', 'Unroll']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(top_16[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa95123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
