{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3387d69",
   "metadata": {},
   "source": [
    "# Test files for Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38803fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead1f472",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_and_transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_and_transform_data(SEED=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of subsets\n",
    "print(f\"X train shape:\\t\", X_train.shape)\n",
    "print(f\"y train shape:\\t\", y_train.shape)\n",
    "print(f\"X val shape:\\t\", X_val.shape)\n",
    "print(f\"y val shape:\\t\", y_val.shape)\n",
    "print(f\"X test shape:\\t\", X_test.shape)\n",
    "print(f\"y test shape:\\t\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f837985",
   "metadata": {},
   "source": [
    "### Initial testing for RNN, LSTM and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3775b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = keras.Sequential()                          # Create a base sequential model\n",
    "RNN.add(keras.Input(shape=(480, 480)))            # Set the input shape\n",
    "RNN.add(layers.SimpleRNN(units=240))      # Add a simple RNN layer\n",
    "RNN.add(layers.Dense(units=1, activation=\"sigmoid\")) # Output layer\n",
    "\n",
    "# Get a summary of model configuration\n",
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM = keras.Sequential()                          # Create a base sequential model\n",
    "LSTM.add(keras.Input(shape=(480, 480)))            # Set the input shape\n",
    "LSTM.add(layers.LSTM(units=240))      # Add a LSTM layer\n",
    "LSTM.add(layers.Dense(units=1, activation=\"sigmoid\")) # Output layer\n",
    "\n",
    "# Get a summary of model configuration\n",
    "LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU = keras.Sequential()                          # Create a base sequential model\n",
    "GRU.add(keras.Input(shape=(480, 480)))            # Set the input shape\n",
    "GRU.add(layers.GRU(units=240))      # Add a GRU layer\n",
    "GRU.add(layers.Dense(units=1, activation=\"sigmoid\")) # Output layer\n",
    "\n",
    "# Get a summary of model configuration\n",
    "GRU.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f504c4e",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "RNN_trainer = RNN.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "RNN_test_loss, RNN_test_acc = RNN.evaluate(X_test, y_test)\n",
    "print(f'RNN Test Accuracy: {RNN_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b418fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "LSTM_trainer = LSTM.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "LSTM_test_loss, LSTM_test_acc = LSTM.evaluate(X_test, y_test)\n",
    "print(f'LSTM Test Accuracy: {LSTM_test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc372fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "GRU_trainer = GRU.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "GRU_test_loss, GRU_test_acc = GRU.evaluate(X_test, y_test)\n",
    "print(f'GRU Test Accuracy: {GRU_test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81787991",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df71294",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(RNN_trainer.history['val_accuracy'], label='RNN Val Accuracy')\n",
    "ax1.plot(LSTM_trainer.history['val_accuracy'], label='LSTM Val Accuracy')\n",
    "ax1.plot(GRU_trainer.history['val_accuracy'], label='GRU Val Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(RNN_trainer.history['val_loss'], label='RNN Val Loss')\n",
    "ax2.plot(LSTM_trainer.history['val_loss'], label='LSTM Val Loss')\n",
    "ax2.plot(GRU_trainer.history['val_loss'], label='GRU Val Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RNN.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# 3. Print test metrics\n",
    "test_loss, test_acc = RNN.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b367c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LSTM.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# 3. Print test metrics\n",
    "test_loss, test_acc = LSTM.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = GRU.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                               display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()\n",
    "\n",
    "# 3. Print test metrics\n",
    "test_loss, test_acc = GRU.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76641c8",
   "metadata": {},
   "source": [
    "## Initial Rough Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1311d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from load_data import load_and_transform_data\n",
    "\n",
    "# Speed optimizations\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create results directory\n",
    "os.makedirs(\"CSV results\", exist_ok=True)\n",
    "\n",
    "# Hyperparameters\n",
    "units = [30, 120, 240, 480]\n",
    "epochs = [5]\n",
    "n_layers = [1, 2, 3]\n",
    "layer_types = [layers.SimpleRNN, layers.GRU]\n",
    "\n",
    "# Generate all layer configurations\n",
    "def generate_layer_configs(n_layers, layer_types, units_options):\n",
    "    configs = []\n",
    "    \n",
    "    for layer_type in layer_types:\n",
    "        if n_layers == 1:\n",
    "            for u in units_options:\n",
    "                configs.append({\n",
    "                    'type': layer_type,\n",
    "                    'units': (u)\n",
    "                })\n",
    "        elif n_layers == 2:\n",
    "            for i, u1 in enumerate(units_options):\n",
    "                for u2 in units_options[:i+1]:\n",
    "                    configs.append({\n",
    "                        'type': layer_type,\n",
    "                        'units': (u1, u2)\n",
    "                    })\n",
    "        elif n_layers == 3:\n",
    "            for i, u1 in enumerate(units_options):\n",
    "                for j, u2 in enumerate(units_options[:i+1]):\n",
    "                    for u3 in units_options[:j+1]:\n",
    "                        configs.append({\n",
    "                            'type': layer_type,\n",
    "                            'units': (u1, u2, u3)\n",
    "                        })\n",
    "    \n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from load_data import load_and_transform_data\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_and_transform_data(SEED=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total combinations\n",
    "layer_configs = []\n",
    "for n_lay in n_layers:\n",
    "    configs = generate_layer_configs(n_lay, layer_types, units)\n",
    "    for config in configs:\n",
    "        layer_configs.append((n_lay, config))\n",
    "\n",
    "total_combinations = len(epochs) * len(layer_configs)\n",
    "print(f\"Total combinations: {total_combinations}\")\n",
    "\n",
    "# Store results\n",
    "results1 = []\n",
    "\n",
    "# Train all models\n",
    "for idx, (ep, (n_lay, layer_config)) in enumerate(tqdm(\n",
    "    itertools.product(epochs, layer_configs), \n",
    "    total=total_combinations)):\n",
    "    \n",
    "    # Clear previous sessions\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Build model based on layer configuration\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(480, 480)))\n",
    "    \n",
    "    # Add layers with varying units\n",
    "    layer_type = layer_config['type']\n",
    "    layer_units = layer_config['units']\n",
    "    \n",
    "    for i, u in enumerate(layer_units):\n",
    "        return_sequences = (i < len(layer_units) - 1)\n",
    "        model.add(layer_type(units=u, return_sequences=return_sequences))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    trainer = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                       epochs=ep, verbose=0)\n",
    "\n",
    "    # Get metrics\n",
    "    val_acc = trainer.history['val_accuracy'][-1]\n",
    "    val_loss = trainer.history['val_loss'][-1]\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    # Create readable string\n",
    "    layer_name = layer_type.__name__\n",
    "    layer_str = ' -> '.join([f\"{layer_name}({u})\" for u in layer_units])\n",
    "\n",
    "    # Store results\n",
    "    results1.append({\n",
    "        'n-Layers': n_lay,\n",
    "        'Layer-Config': layer_str,\n",
    "        'Units': str(layer_units),\n",
    "        'n-Epochs': ep,\n",
    "        'Val Accuracy': val_acc,\n",
    "        'Val Loss': val_loss,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Test Loss': test_loss\n",
    "    })\n",
    "    \n",
    "    # Save progress\n",
    "    pd.DataFrame(results1).to_csv(\"CSV results/GRU_results_rough_temp.csv\", index=False)\n",
    "\n",
    "# Save final results\n",
    "df_results1 = pd.DataFrame(results1)\n",
    "df_results1.to_csv(\"CSV results/GRU_results_rough.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 20\n",
    "top_20 = df_results1.nlargest(20, 'Test Accuracy')\n",
    "print(f\"\\nComplete! {len(results1)} models trained\")\n",
    "print(\"\\nTop 20:\")\n",
    "print(top_20[['Layer-Config', 'Val Accuracy', 'Test Accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa95123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "dropout = [0.0, 0.15, 0.3]\n",
    "recurrent_dropout = [0.0, 0.15, 0.3]\n",
    "batch_sizes = [32]\n",
    "epochs = [5]\n",
    "\n",
    "# Fixed layer config\n",
    "fixed_layer_type = layers.GRU\n",
    "fixed_units = (240, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total combinations\n",
    "total_combinations = len(dropout) * len(recurrent_dropout) * len(batch_sizes) * len(epochs)\n",
    "print(f\"Total combinations: {total_combinations}\")\n",
    "\n",
    "# Store results\n",
    "results_dropout = []\n",
    "\n",
    "# Train all models\n",
    "for drop, rec_drop, bs, ep in tqdm(itertools.product(dropout, recurrent_dropout, batch_sizes, epochs), \n",
    "                                    total=total_combinations):\n",
    "    \n",
    "    # Clear previous sessions\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Build model with fixed architecture\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(480, 480)))\n",
    "    \n",
    "    # Add GRU layers with dropout\n",
    "    model.add(fixed_layer_type(units=fixed_units[0], dropout=drop, recurrent_dropout=rec_drop, return_sequences=True))\n",
    "    model.add(fixed_layer_type(units=fixed_units[1], dropout=drop, recurrent_dropout=rec_drop))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "  \n",
    "    # Train\n",
    "    trainer = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                       epochs=ep, verbose=0, batch_size=bs)\n",
    "\n",
    "    # Get metrics\n",
    "    val_acc = trainer.history['val_accuracy'][-1]\n",
    "    val_loss = trainer.history['val_loss'][-1]\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0, batch_size=bs)\n",
    "\n",
    "    # Store results\n",
    "    results_dropout.append({\n",
    "        'Layer-Config': 'GRU(240) -> GRU(120)',\n",
    "        'Dropout': drop,\n",
    "        'Recurrent-Dropout': rec_drop,\n",
    "        'Batch-Size': bs,\n",
    "        'n-Epochs': ep,\n",
    "        'Val Accuracy': val_acc,\n",
    "        'Val Loss': val_loss,\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Test Loss': test_loss\n",
    "    })\n",
    "    \n",
    "    # Save progress\n",
    "    pd.DataFrame(results_dropout).to_csv(\"CSV results/RNN_dropout_results_temp.csv\", index=False)\n",
    "\n",
    "# Save final results\n",
    "df_results_dropout = pd.DataFrame(results_dropout)\n",
    "df_results_dropout.to_csv(\"CSV results/RNN_dropout_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20129b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top results\n",
    "top_10 = df_results_dropout.nlargest(10, 'Test Accuracy')\n",
    "print(f\"\\nComplete! {len(results_dropout)} models trained\")\n",
    "print(\"\\nTop 10:\")\n",
    "print(top_10[['Dropout', 'Recurrent-Dropout', 'Val Accuracy', 'Test Accuracy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84beb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Widths in inches from revtex4's layout\n",
    "columnwidth = 4.375\n",
    "fig_width = columnwidth\n",
    "fig_height = columnwidth / 1.618\n",
    "fig_size = [fig_width, fig_height]\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],\n",
    "    \"font.size\": 14.0, \n",
    "    \"axes.labelsize\": 14.0,\n",
    "    \"legend.fontsize\": 12.0,\n",
    "    \"xtick.labelsize\": 12.0,\n",
    "    \"ytick.labelsize\": 12.0,\n",
    "    \"figure.figsize\": fig_size,\n",
    "    \"savefig.dpi\": 300,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40158a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_architecture = pd.read_csv(\"CSV results/GRU_results_rough.csv\")\n",
    "\n",
    "# Parse units and layer type\n",
    "df_architecture['First_Layer_Units'] = df_architecture['Units'].apply(lambda x: eval(x)[0])\n",
    "df_architecture['Layer_Type'] = df_architecture['Layer-Config'].apply(lambda x: 'GRU' if 'GRU' in x else 'SimpleRNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter only 2-layer GRU configurations\n",
    "df_gru_2layer = df_architecture[(df_architecture['Layer_Type'] == 'GRU') & \n",
    "                                 (df_architecture['n-Layers'] == 2)].copy()\n",
    "\n",
    "# Parse second layer units\n",
    "df_gru_2layer['Second_Layer_Units'] = df_gru_2layer['Units'].apply(lambda x: eval(x)[1])\n",
    "\n",
    "# Create pivot table: First layer units (rows) x Second layer units (columns)\n",
    "pivot_gru_units = df_gru_2layer.pivot_table(\n",
    "    values='Test Accuracy',\n",
    "    index='First_Layer_Units',\n",
    "    columns='Second_Layer_Units',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(columnwidth, columnwidth*(3/4)))\n",
    "sns.heatmap(pivot_gru_units, annot=True, fmt='.3f', ax=ax, cmap=\"Greens\",\n",
    "            vmin=0.88, vmax=0.92)\n",
    "ax.set_title(\"GRU 2-Layer: Unit Size Combinations\", fontsize=14, pad=15)\n",
    "ax.set_ylabel(\"First Layer Units\", fontsize=12)\n",
    "ax.set_xlabel(\"Second Layer Units\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61efba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= PLOT 1: GRU vs SimpleRNN =============\n",
    "pivot_comparison = df_architecture.pivot_table(\n",
    "    values='Test Accuracy',\n",
    "    index=['Layer_Type', 'n-Layers'],\n",
    "    columns='First_Layer_Units',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(columnwidth*1.05, columnwidth*(3/4)))\n",
    "sns.heatmap(pivot_comparison, annot=True, fmt='.3f', ax=ax, cmap=\"Greens\")\n",
    "ax.set_title(\"GRU vs SimpleRNN Performance\", fontsize=14, pad=15)\n",
    "ax.set_xlabel(\"Units in First Layer\", fontsize=12)\n",
    "ax.set_ylabel(\"Layer Type and Depth\", fontsize=12)\n",
    "plt.yticks(rotation=0, va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebae1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============= PLOT 2: Simplified Comparison - Average by Type and Depth =============\n",
    "summary = df_architecture.groupby(['Layer_Type', 'n-Layers'])['Test Accuracy'].mean().reset_index()\n",
    "pivot_simple = summary.pivot(index='n-Layers', columns='Layer_Type', values='Test Accuracy')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(columnwidth*0.8, columnwidth*(3/4)))\n",
    "sns.heatmap(pivot_simple, annot=True, fmt='.3f', ax=ax, cmap=\"Greens\",\n",
    "            vmin=0.7, vmax=0.9)\n",
    "ax.set_title(\"Average Performance by Type and Depth\", fontsize=14, pad=15)\n",
    "ax.set_ylabel(\"Number of Layers\", fontsize=12)\n",
    "ax.set_xlabel(\"Layer Type\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============= PLOT 3: Separate Heatmaps for GRU and SimpleRNN =============\n",
    "for layer_type in ['GRU', 'SimpleRNN']:\n",
    "    df_subset = df_architecture[df_architecture['Layer_Type'] == layer_type]\n",
    "    \n",
    "    pivot = df_subset.pivot_table(\n",
    "        values='Test Accuracy',\n",
    "        index='First_Layer_Units',\n",
    "        columns='n-Layers',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(columnwidth*0.8, columnwidth*(3/4)))\n",
    "    sns.heatmap(pivot, annot=True, fmt='.3f', ax=ax, cmap=\"Greens\",\n",
    "                vmin=0.6, vmax=0.95)\n",
    "    ax.set_title(f\"{layer_type} Architecture Analysis\", fontsize=14, pad=15)\n",
    "    ax.set_ylabel(\"Units in First Layer\", fontsize=12)\n",
    "    ax.set_xlabel(\"Number of Layers (Depth)\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87095a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dropout results\n",
    "df_dropout = pd.read_csv(\"CSV results/RNN_dropout_results.csv\")\n",
    "\n",
    "# Create pivot table for heatmap\n",
    "pivot_dropout = df_dropout.pivot_table(\n",
    "    values='Test Accuracy',\n",
    "    index='Dropout',\n",
    "    columns='Recurrent-Dropout',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(columnwidth*1.2, columnwidth*(3/4)))\n",
    "sns.heatmap(pivot_dropout, annot=True, fmt='.3f', ax=ax, cmap=\"Greens\")\n",
    "ax.set_title(\"Test Accuracy Dropout vs Recurrent Dropout\", fontsize=14, pad=15)\n",
    "ax.set_xlabel(\"Recurrent Dropout\", fontsize=12)\n",
    "ax.set_ylabel(\"Dropout\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a4a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
