{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf44d7e",
   "metadata": {},
   "source": [
    "# Testing FFNN on classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae9e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from activation_functions import *\n",
    "from cost_functions import *\n",
    "from FFNN import *\n",
    "\n",
    "# Setting the random seed\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5336aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 784)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "# Extract data (features) and target (labels)\n",
    "X = mnist.data[:2500]\n",
    "y = mnist.target[:2500]\n",
    "\n",
    "# Scaling the mnist pixel values from 0-255 to 0-1\n",
    "X = X / 255.0\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aeb0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into testing, training and validation sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_one_hot(y_train)\n",
    "y_test = to_one_hot(y_test)\n",
    "y_val = to_one_hot(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1f60b",
   "metadata": {},
   "source": [
    "# Testing parameter combinations with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc7a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into testing an training sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_one_hot(y_train)\n",
    "y_test = to_one_hot(y_test)\n",
    "y_val = to_one_hot(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f8c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "layer_sizes = [25, 250, 1000]\n",
    "num_hidden_layers = [0, 1, 2, 3]\n",
    "etas = np.logspace(-1, -2, num=2)\n",
    "activation_functions = [sigmoid, ReLU, leaky_ReLU]\n",
    "epochs = [100]\n",
    "optimizers = [train_network_SRMSprop, train_network_stocastic_ADAM]\n",
    "cost_functions = [cross_entropy]\n",
    "\n",
    "network_input_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebc2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/144 [00:04<03:38,  1.55s/it]c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: divide by zero encountered in log\n",
      "  return f_raw(*args, **kwargs)\n",
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: invalid value encountered in multiply\n",
      "  return f_raw(*args, **kwargs)\n",
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  defvjp(anp.log, lambda ans, x: lambda g: g / x)\n",
      " 33%|███▎      | 48/144 [01:14<02:28,  1.55s/it]c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:125: RuntimeWarning: overflow encountered in square\n",
      "  lambda ans, x, y: unbroadcast_f(y, lambda g: -g * x / y**2),\n",
      " 34%|███▍      | 49/144 [01:16<02:48,  1.78s/it]c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: overflow encountered in exp\n",
      "  return f_raw(*args, **kwargs)\n",
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:160: RuntimeWarning: invalid value encountered in multiply\n",
      "  defvjp(anp.exp, lambda ans, x: lambda g: ans * g)\n",
      " 46%|████▌     | 66/144 [02:34<15:55, 12.24s/it]c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:163: RuntimeWarning: divide by zero encountered in divide\n",
      "  defvjp(anp.log, lambda ans, x: lambda g: g / x)\n",
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:125: RuntimeWarning: invalid value encountered in multiply\n",
      "  lambda ans, x, y: unbroadcast_f(y, lambda g: -g * x / y**2),\n",
      " 57%|█████▋    | 82/144 [09:42<47:33, 46.03s/it]c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\tracer.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  return f_raw(*args, **kwargs)\n",
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:125: RuntimeWarning: divide by zero encountered in divide\n",
      "  lambda ans, x, y: unbroadcast_f(y, lambda g: -g * x / y**2),\n",
      "c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:125: RuntimeWarning: invalid value encountered in divide\n",
      "  lambda ans, x, y: unbroadcast_f(y, lambda g: -g * x / y**2),\n",
      " 80%|███████▉  | 115/144 [26:33<06:55, 14.32s/it] c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:163: RuntimeWarning: overflow encountered in divide\n",
      "  defvjp(anp.log, lambda ans, x: lambda g: g / x)\n",
      " 85%|████████▌ | 123/144 [29:24<07:07, 20.38s/it]c:\\Users\\eirik\\Desktop\\FYSSTK3155_Dataprocessing_and_MachineLearning\\Project2_FYSSTK3155-4155\\.venv\\Lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:124: RuntimeWarning: overflow encountered in divide\n",
      "  lambda ans, x, y: unbroadcast_f(x, lambda g: g / y),\n",
      "100%|██████████| 144/144 [1:06:43<00:00, 27.80s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_combinations = len(list(itertools.product(num_hidden_layers, layer_sizes, etas, activation_functions, epochs, optimizers)))\n",
    "\n",
    "# Store results\n",
    "results1 = []\n",
    "\n",
    "for _, (num_layers, num_nodes, eta, act_func, num_epochs, optimizer) in enumerate(tqdm(itertools.product(num_hidden_layers, layer_sizes, etas, activation_functions, epochs, optimizers), total=total_combinations)):\n",
    "\n",
    "    # If no hidden layers\n",
    "    if num_layers == 0:\n",
    "            layer_output_sizes = [10]\n",
    "            activation_funcs = [softmax]\n",
    "    else:\n",
    "        # Hidden layers + output layer\n",
    "        layer_output_sizes = [num_nodes] * num_layers + [10]\n",
    "        activation_funcs = [act_func] * num_layers + [softmax]\n",
    "\n",
    "    # Create and train network\n",
    "    NN = NeuralNetwork(network_input_size, layer_output_sizes, activation_funcs, cross_entropy)\n",
    "\n",
    "    optimizer(NN, X_train, y_train, eta=eta, epochs=num_epochs)\n",
    "\n",
    "    train_pred = NN.predict(X_train)\n",
    "    val_pred = NN.predict(X_val)\n",
    "    test_pred = NN.predict(X_test)\n",
    "    \n",
    "    train_accuracy = accuracy(train_pred, y_train)\n",
    "    val_accuracy = accuracy(val_pred, y_val)\n",
    "    test_accuracy = accuracy(test_pred, y_test)\n",
    "\n",
    "    # Store results\n",
    "    results1.append({\n",
    "        'n_hidden': num_layers,\n",
    "        'layer_size': num_nodes,\n",
    "        'eta': eta,\n",
    "        'activation': act_func.__name__,\n",
    "        'n_epochs': num_epochs,\n",
    "        'optimizer': optimizer.__name__,\n",
    "        'train_acc': train_accuracy,\n",
    "        'val_acc': val_accuracy,\n",
    "        'test_acc': test_accuracy\n",
    "    })\n",
    "\n",
    "# Evaluate results\n",
    "df_results1 = pd.DataFrame(results1)\n",
    "\n",
    "# Save results to file\n",
    "df_results1.to_csv(\"Mnist2500_results_rough.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3a7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>eta</th>\n",
       "      <th>activation</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.987333</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.948667</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.994667</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.980667</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.971333</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.931333</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.978667</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>leaky_ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>softmax</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.981333</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.977333</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_hidden  layer_size   eta  activation  n_epochs  \\\n",
       "72          1         250  0.01     sigmoid       100   \n",
       "73          1         250  0.01     sigmoid       100   \n",
       "88          1        1000  0.01     sigmoid       100   \n",
       "120         2         250  0.01     sigmoid       100   \n",
       "136         2        1000  0.01     sigmoid       100   \n",
       "121         2         250  0.01     sigmoid       100   \n",
       "104         2          25  0.01     sigmoid       100   \n",
       "56          1          25  0.01     sigmoid       100   \n",
       "80          1        1000  0.10     sigmoid       100   \n",
       "89          1        1000  0.01     sigmoid       100   \n",
       "105         2          25  0.01     sigmoid       100   \n",
       "25          0         250  0.01     sigmoid       100   \n",
       "41          0        1000  0.01     sigmoid       100   \n",
       "12          0          25  0.01  leaky_ReLU       100   \n",
       "64          1         250  0.10     sigmoid       100   \n",
       "106         2          25  0.01        ReLU       100   \n",
       "21          0         250  0.10  leaky_ReLU       100   \n",
       "109         2          25  0.01  leaky_ReLU       100   \n",
       "111         2          25  0.01     softmax       100   \n",
       "48          1          25  0.10     sigmoid       100   \n",
       "26          0         250  0.01        ReLU       100   \n",
       "31          0         250  0.01     softmax       100   \n",
       "40          0        1000  0.01     sigmoid       100   \n",
       "142         2        1000  0.01     softmax       100   \n",
       "94          1        1000  0.01     softmax       100   \n",
       "7           0          25  0.10     softmax       100   \n",
       "9           0          25  0.01     sigmoid       100   \n",
       "13          0          25  0.01  leaky_ReLU       100   \n",
       "57          1          25  0.01     sigmoid       100   \n",
       "1           0          25  0.10     sigmoid       100   \n",
       "18          0         250  0.10        ReLU       100   \n",
       "6           0          25  0.10     softmax       100   \n",
       "11          0          25  0.01        ReLU       100   \n",
       "28          0         250  0.01  leaky_ReLU       100   \n",
       "30          0         250  0.01     softmax       100   \n",
       "46          0        1000  0.01     softmax       100   \n",
       "96          2          25  0.10     sigmoid       100   \n",
       "8           0          25  0.01     sigmoid       100   \n",
       "24          0         250  0.01     sigmoid       100   \n",
       "0           0          25  0.10     sigmoid       100   \n",
       "5           0          25  0.10  leaky_ReLU       100   \n",
       "22          0         250  0.10     softmax       100   \n",
       "23          0         250  0.10     softmax       100   \n",
       "33          0        1000  0.10     sigmoid       100   \n",
       "47          0        1000  0.01     softmax       100   \n",
       "60          1          25  0.01  leaky_ReLU       100   \n",
       "2           0          25  0.10        ReLU       100   \n",
       "38          0        1000  0.10     softmax       100   \n",
       "19          0         250  0.10        ReLU       100   \n",
       "10          0          25  0.01        ReLU       100   \n",
       "\n",
       "                        optimizer  train_acc  val_acc  test_acc  \n",
       "72         train_network_SRMSprop   0.999333    0.920     0.910  \n",
       "73   train_network_stocastic_ADAM   0.996667    0.912     0.908  \n",
       "88         train_network_SRMSprop   0.994000    0.906     0.914  \n",
       "120        train_network_SRMSprop   0.988000    0.906     0.894  \n",
       "136        train_network_SRMSprop   0.972667    0.904     0.866  \n",
       "121  train_network_stocastic_ADAM   0.987333    0.898     0.892  \n",
       "104        train_network_SRMSprop   0.999333    0.894     0.870  \n",
       "56         train_network_SRMSprop   0.999333    0.878     0.844  \n",
       "80         train_network_SRMSprop   0.948667    0.874     0.814  \n",
       "89   train_network_stocastic_ADAM   0.994667    0.874     0.896  \n",
       "105  train_network_stocastic_ADAM   0.995333    0.870     0.876  \n",
       "25   train_network_stocastic_ADAM   0.993333    0.866     0.872  \n",
       "41   train_network_stocastic_ADAM   0.994667    0.866     0.812  \n",
       "12         train_network_SRMSprop   0.996667    0.864     0.846  \n",
       "64         train_network_SRMSprop   0.926667    0.864     0.808  \n",
       "106        train_network_SRMSprop   0.966000    0.864     0.858  \n",
       "21   train_network_stocastic_ADAM   0.980667    0.860     0.836  \n",
       "109  train_network_stocastic_ADAM   0.971333    0.854     0.802  \n",
       "111  train_network_stocastic_ADAM   0.894000    0.852     0.812  \n",
       "48         train_network_SRMSprop   0.956000    0.850     0.858  \n",
       "26         train_network_SRMSprop   0.995333    0.848     0.836  \n",
       "31   train_network_stocastic_ADAM   0.993333    0.848     0.856  \n",
       "40         train_network_SRMSprop   0.998667    0.848     0.844  \n",
       "142        train_network_SRMSprop   0.883333    0.848     0.826  \n",
       "94         train_network_SRMSprop   0.853333    0.846     0.826  \n",
       "7    train_network_stocastic_ADAM   0.984667    0.844     0.840  \n",
       "9    train_network_stocastic_ADAM   0.988667    0.844     0.858  \n",
       "13   train_network_stocastic_ADAM   0.995333    0.844     0.798  \n",
       "57   train_network_stocastic_ADAM   0.995333    0.844     0.832  \n",
       "1    train_network_stocastic_ADAM   0.970000    0.842     0.834  \n",
       "18         train_network_SRMSprop   0.984000    0.842     0.840  \n",
       "6          train_network_SRMSprop   0.992000    0.838     0.794  \n",
       "11   train_network_stocastic_ADAM   0.990000    0.838     0.846  \n",
       "28         train_network_SRMSprop   0.996667    0.838     0.836  \n",
       "30         train_network_SRMSprop   0.991333    0.838     0.842  \n",
       "46         train_network_SRMSprop   0.993333    0.836     0.820  \n",
       "96         train_network_SRMSprop   0.931333    0.834     0.850  \n",
       "8          train_network_SRMSprop   0.997333    0.832     0.834  \n",
       "24         train_network_SRMSprop   0.998000    0.832     0.860  \n",
       "0          train_network_SRMSprop   0.978667    0.830     0.816  \n",
       "5    train_network_stocastic_ADAM   0.974667    0.830     0.842  \n",
       "22         train_network_SRMSprop   0.986667    0.830     0.828  \n",
       "23   train_network_stocastic_ADAM   0.977333    0.830     0.812  \n",
       "33   train_network_stocastic_ADAM   0.972667    0.830     0.826  \n",
       "47   train_network_stocastic_ADAM   0.992000    0.830     0.810  \n",
       "60         train_network_SRMSprop   0.986000    0.830     0.854  \n",
       "2          train_network_SRMSprop   0.976000    0.828     0.800  \n",
       "38         train_network_SRMSprop   0.981333    0.826     0.842  \n",
       "19   train_network_stocastic_ADAM   0.977333    0.824     0.842  \n",
       "10         train_network_SRMSprop   0.998667    0.822     0.830  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the results from CSV\n",
    "df_results1 = pd.read_csv(\"Mnist2500_results_rough.csv\")\n",
    "\n",
    "# Get top 25 configurations\n",
    "top_50 = df_results1.nlargest(50, 'val_acc').copy()\n",
    "top_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5628050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_hidden\n",
      "0    29\n",
      "1    11\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "layer_size\n",
      "25      22\n",
      "250     16\n",
      "1000    12\n",
      "Name: count, dtype: int64\n",
      "eta\n",
      "0.01    33\n",
      "0.10    17\n",
      "Name: count, dtype: int64\n",
      "activation\n",
      "sigmoid       24\n",
      "softmax       12\n",
      "leaky_ReLU     7\n",
      "ReLU           7\n",
      "Name: count, dtype: int64\n",
      "optimizer\n",
      "train_network_SRMSprop          29\n",
      "train_network_stocastic_ADAM    21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(top_50['n_hidden'].value_counts())\n",
    "print(top_50['layer_size'].value_counts())\n",
    "print(top_50['eta'].value_counts())\n",
    "print(top_50['activation'].value_counts())\n",
    "print(top_50['optimizer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd887c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "layer_sizes = [25, 100, 250, 500, 1000]\n",
    "num_hidden_layers = [0, 1, 2, 3, 4]\n",
    "etas = [0.01]\n",
    "activation_functions = [sigmoid]\n",
    "epochs = [100]\n",
    "optimizers = [train_network_SRMSprop, train_network_stocastic_ADAM, train_network_stocastic_momentum, train_network_momentum]\n",
    "cost_functions = [cross_entropy]\n",
    "\n",
    "network_input_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb38775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [50:59<00:00, 95.60s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_combinations = len(list(itertools.product(num_hidden_layers, layer_sizes, etas, activation_functions, epochs, optimizers)))\n",
    "\n",
    "# Store results\n",
    "results2 = []\n",
    "\n",
    "for _, (num_layers, num_nodes, eta, act_func, num_epochs, optimizer) in enumerate(tqdm(itertools.product(num_hidden_layers, layer_sizes, etas, activation_functions, epochs, optimizers), total=total_combinations)):\n",
    "\n",
    "    # If no hidden layers\n",
    "    if num_layers == 0:\n",
    "            layer_output_sizes = [10]\n",
    "            activation_funcs = [softmax]\n",
    "    else:\n",
    "        # Hidden layers + output layer\n",
    "        layer_output_sizes = [num_nodes] * num_layers + [10]\n",
    "        activation_funcs = [act_func] * num_layers + [softmax]\n",
    "\n",
    "    # Create and train network\n",
    "    NN = NeuralNetwork(network_input_size, layer_output_sizes, activation_funcs, cross_entropy)\n",
    "\n",
    "    optimizer(NN, X_train, y_train, eta=eta, epochs=num_epochs)\n",
    "\n",
    "    train_pred = NN.predict(X_train)\n",
    "    val_pred = NN.predict(X_val)\n",
    "    test_pred = NN.predict(X_test)\n",
    "    \n",
    "    train_accuracy = accuracy(train_pred, y_train)\n",
    "    val_accuracy = accuracy(val_pred, y_val)\n",
    "    test_accuracy = accuracy(test_pred, y_test)\n",
    "\n",
    "    # Store results\n",
    "    results2.append({\n",
    "        'n_hidden': num_layers,\n",
    "        'layer_size': num_nodes,\n",
    "        'eta': eta,\n",
    "        'activation': act_func.__name__,\n",
    "        'n_epochs': num_epochs,\n",
    "        'optimizer': optimizer.__name__,\n",
    "        'train_acc': train_accuracy,\n",
    "        'val_acc': val_accuracy,\n",
    "        'test_acc': test_accuracy\n",
    "    })\n",
    "\n",
    "# Evaluate results\n",
    "df_results2 = pd.DataFrame(results2)\n",
    "\n",
    "# Save results to file\n",
    "df_results2.to_csv(\"Mnist2500_results_depth.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "637b927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>layer_size</th>\n",
       "      <th>eta</th>\n",
       "      <th>activation</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.986000</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_stocastic_ADAM</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>100</td>\n",
       "      <td>train_network_SRMSprop</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_hidden  layer_size   eta activation  n_epochs  \\\n",
       "14         1         500  0.01    sigmoid       100   \n",
       "28         3         250  0.01    sigmoid       100   \n",
       "15         1         500  0.01    sigmoid       100   \n",
       "20         2         250  0.01    sigmoid       100   \n",
       "10         1         100  0.01    sigmoid       100   \n",
       "19         2         100  0.01    sigmoid       100   \n",
       "21         2         250  0.01    sigmoid       100   \n",
       "22         2         500  0.01    sigmoid       100   \n",
       "30         3         500  0.01    sigmoid       100   \n",
       "26         3         100  0.01    sigmoid       100   \n",
       "\n",
       "                       optimizer  train_acc  val_acc  test_acc  \n",
       "14        train_network_SRMSprop   0.996667    0.932     0.898  \n",
       "28        train_network_SRMSprop   0.994000    0.912     0.890  \n",
       "15  train_network_stocastic_ADAM   0.996000    0.908     0.898  \n",
       "20        train_network_SRMSprop   0.986000    0.908     0.874  \n",
       "10        train_network_SRMSprop   0.998667    0.902     0.888  \n",
       "19  train_network_stocastic_ADAM   0.998000    0.902     0.876  \n",
       "21  train_network_stocastic_ADAM   0.992667    0.902     0.896  \n",
       "22        train_network_SRMSprop   0.984667    0.902     0.878  \n",
       "30        train_network_SRMSprop   0.964000    0.900     0.888  \n",
       "26        train_network_SRMSprop   0.996667    0.896     0.886  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 configurations\n",
    "top_10 = df_results2.nlargest(10, 'val_acc').copy()\n",
    "top_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96661716",
   "metadata": {},
   "source": [
    "## Network architecture heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e827a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 337.5x220 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the results from CSV\n",
    "df_results = pd.read_csv(\"Mnist2500_results_depth.csv\")\n",
    "\n",
    "# Get unique values for the axes (switched)\n",
    "num_hidden_layers = sorted(df_results['n_hidden'].unique())\n",
    "layer_sizes = sorted(df_results['layer_size'].unique())\n",
    "\n",
    "# Create 2D array for heatmap (dimensions switched)\n",
    "results = np.zeros((len(num_hidden_layers), len(layer_sizes)))\n",
    "\n",
    "# Fill the results array with validation accuracy (indices switched)\n",
    "for i, num_layers in enumerate(num_hidden_layers):\n",
    "    for j, layer_size in enumerate(layer_sizes):\n",
    "        # Filter for this specific combination\n",
    "        mask = (df_results['n_hidden'] == num_layers) & (df_results['layer_size'] == layer_size)\n",
    "        \n",
    "        if mask.any():\n",
    "            # If multiple results exist for this combination, take the best validation accuracy\n",
    "            results[i, j] = df_results[mask]['val_acc'].max()\n",
    "        else:\n",
    "            results[i, j] = np.nan\n",
    "\n",
    "# Create heatmap with new formatting (labels switched)\n",
    "fig, ax = plt.subplots(figsize=(3.375, 2.2))  # width x height in inches\n",
    "sns.heatmap(results, annot=True, fmt='.3f', cmap='YlGnBu',\n",
    "            xticklabels=layer_sizes,\n",
    "            yticklabels=num_hidden_layers,\n",
    "            cbar_kws={'label': 'Validation Accuracy'},\n",
    "            annot_kws={'size': 7}, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Nodes per Hidden Layer')\n",
    "ax.set_ylabel('# Hidden Layers')\n",
    "ax.set_title('Effect of network depth', pad=6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecef0c",
   "metadata": {},
   "source": [
    "## Activation function test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d287299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "layer_sizes = [25, 100, 250, 500]\n",
    "num_hidden_layers = [0, 1, 2, 3]\n",
    "etas = [0.01]\n",
    "activation_functions = [sigmoid]\n",
    "epochs = [100]\n",
    "optimizers = [train_network_SRMSprop, train_network_stocastic_ADAM]\n",
    "cost_functions = [cross_entropy]\n",
    "\n",
    "network_input_size = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc80947",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_combinations = len(list(itertools.product(num_hidden_layers, layer_sizes, etas, activation_functions, epochs, optimizers)))\n",
    "\n",
    "# Store results\n",
    "results3 = []\n",
    "\n",
    "for _, (num_layers, num_nodes, eta, act_func, num_epochs, optimizer) in enumerate(tqdm(itertools.product(num_hidden_layers, layer_sizes, etas, activation_functions, epochs, optimizers), total=total_combinations)):\n",
    "\n",
    "    # If no hidden layers\n",
    "    if num_layers == 0:\n",
    "            layer_output_sizes = [10]\n",
    "            activation_funcs = [softmax]\n",
    "    else:\n",
    "        # Hidden layers + output layer\n",
    "        layer_output_sizes = [num_nodes] * num_layers + [10]\n",
    "        activation_funcs = [act_func] * num_layers + [softmax]\n",
    "\n",
    "    # Create and train network\n",
    "    NN = NeuralNetwork(network_input_size, layer_output_sizes, activation_funcs, cross_entropy)\n",
    "\n",
    "    optimizer(NN, X_train, y_train, eta=eta, epochs=num_epochs)\n",
    "\n",
    "    train_pred = NN.predict(X_train)\n",
    "    val_pred = NN.predict(X_val)\n",
    "    test_pred = NN.predict(X_test)\n",
    "    \n",
    "    train_accuracy = accuracy(train_pred, y_train)\n",
    "    val_accuracy = accuracy(val_pred, y_val)\n",
    "    test_accuracy = accuracy(test_pred, y_test)\n",
    "\n",
    "    # Store results\n",
    "    results2.append({\n",
    "        'n_hidden': num_layers,\n",
    "        'layer_size': num_nodes,\n",
    "        'eta': eta,\n",
    "        'activation': act_func.__name__,\n",
    "        'n_epochs': num_epochs,\n",
    "        'optimizer': optimizer.__name__,\n",
    "        'train_acc': train_accuracy,\n",
    "        'val_acc': val_accuracy,\n",
    "        'test_acc': test_accuracy\n",
    "    })\n",
    "\n",
    "# Evaluate results\n",
    "df_results2 = pd.DataFrame(results3)\n",
    "\n",
    "# Save results to file\n",
    "df_results2.to_csv(\"Mnist2500_results_optim.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
